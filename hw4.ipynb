{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d0a5ef-318d-43b0-b0af-2122e82063b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moogedelic/miniforge3/envs/llm_camp_env/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0745f89a-6810-4025-b47a-982382b041c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The context does not provide any specific info...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  You can sign up for the course by visiting the...   \n",
       "1  You can sign up using the link provided in the...   \n",
       "2  Yes, there is an FAQ for the Machine Learning ...   \n",
       "3  The context does not provide any specific info...   \n",
       "4  To structure your questions and answers for th...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "3  Does this course have a GitHub repository for ...   \n",
       "4  How can I structure my questions and answers f...   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  \n",
       "3  machine-learning-zoomcamp  \n",
       "4  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/04-monitoring/data/results-gpt4o-mini.csv'\n",
    "url = f'{github_url}?raw=1'\n",
    "df = pd.read_csv(url)\n",
    "df = df.iloc[:300]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bdbc309-bc39-4fd7-8c19-03ca5e822a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multi-qa-mpnet-base-dot-v1'\n",
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bba5b9b5-ad63-4082-b8a5-4f2c29d02cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_llm = df.iloc[0].answer_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf5dbe8-d403-473c-9fc2-017e5aaad923",
   "metadata": {},
   "source": [
    "What's the first value of the resulting vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37fd204a-ed71-4a87-a1dd-d84ae49dc525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.42244664"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = embedding_model.encode(answer_llm)\n",
    "embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efac716e-b880-4003-b0e8-d15293d6940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(answer_orig, answer_llm):\n",
    "    v_llm = embedding_model.encode(answer_llm)\n",
    "    v_orig = embedding_model.encode(answer_orig)\n",
    "    \n",
    "    return v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "800b26b0-0f11-412d-bb24-755ddc388971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efe22aa1cf4420490b38716fbf1bc4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for index, record in tqdm(df.iterrows(), total=len(df)):\n",
    "    sim = compute_similarity(record['answer_orig'], record['answer_llm'])\n",
    "    evaluations.append(sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87eca53c-86fd-489e-939c-a1e9f845315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 75th percentile of evaluations is: 31.674304008483887\n"
     ]
    }
   ],
   "source": [
    "percentile_75 = np.percentile(evaluations, 75)\n",
    "\n",
    "print(f\"The 75th percentile of evaluations is: {percentile_75}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9ace987-8528-44e5-bfd9-ae2aee1d05a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector(v):\n",
    "    norm = np.sqrt((v * v).sum())\n",
    "    return v / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "284795da-0f81-41b7-b69b-95e3af4e8776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_normalized(answer_orig, answer_llm):\n",
    "    v_llm = embedding_model.encode(answer_llm)\n",
    "    v_orig = embedding_model.encode(answer_orig)\n",
    "    \n",
    "    # Normalize the vectors\n",
    "    v_llm_norm = normalize_vector(v_llm)\n",
    "    v_orig_norm = normalize_vector(v_orig)\n",
    "    \n",
    "    # Compute the similarity (dot product) between the normalized vectors\n",
    "    similarity = np.dot(v_llm_norm, v_orig_norm)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e730c020-7c5e-423b-b909-b4e2d965559b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61be2d58ac2d44a59e36e5aa6e1ae0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "evaluations = []\n",
    "\n",
    "for index, record in tqdm(df.iterrows(), total=len(df)):\n",
    "    sim = compute_similarity_normalized(record['answer_orig'], record['answer_llm'])\n",
    "    evaluations.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9415b513-156b-4a29-95ef-3cc03569c6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 75th percentile of evaluations is: 0.8362347632646561\n"
     ]
    }
   ],
   "source": [
    "# Calculate the 75th percentile of evaluations\n",
    "percentile_75 = np.percentile(evaluations, 75)\n",
    "print(f\"The 75th percentile of evaluations is: {percentile_75}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3673a334-f90f-44fc-9ae6-32d6594b4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scorer = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1175098-9b6c-4e46-8a14-9b02136671a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute ROUGE score between two texts\n",
    "def compute_rouge_score(answer_llm, answer_orig):\n",
    "    scores = rouge_scorer.get_scores(answer_llm, answer_orig)[0]\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c7d3d8a-fdba-4d8d-9579-e36db011e27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores at index 10: {'rouge-1': {'r': 0.45454545454545453, 'p': 0.45454545454545453, 'f': 0.45454544954545456}, 'rouge-2': {'r': 0.21621621621621623, 'p': 0.21621621621621623, 'f': 0.21621621121621637}, 'rouge-l': {'r': 0.3939393939393939, 'p': 0.3939393939393939, 'f': 0.393939388939394}}\n"
     ]
    }
   ],
   "source": [
    "# Access the answers at the specific index (10)\n",
    "index = 10\n",
    "answer_llm = df.loc[index, 'answer_llm']\n",
    "answer_orig = df.loc[index, 'answer_orig']\n",
    "\n",
    "# Compute the ROUGE score\n",
    "scores = compute_rouge_score(answer_llm, answer_orig)\n",
    "\n",
    "print(f\"ROUGE scores at index {index}: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7538505b-8516-4e5d-9288-eb776e9fffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute ROUGE scores between two texts\n",
    "def compute_rouge_scores(answer_llm, answer_orig):\n",
    "    scores = rouge_scorer.get_scores(answer_llm, answer_orig)[0]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "058246f1-92d6-47c9-9cf5-d93564ab5a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the average of ROUGE-1, ROUGE-2, and ROUGE-L scores\n",
    "def compute_average_rouge(scores):\n",
    "    rouge_1_f1 = scores['rouge-1']['f']\n",
    "    rouge_2_f1 = scores['rouge-2']['f']\n",
    "    rouge_l_f1 = scores['rouge-l']['f']\n",
    "    \n",
    "    average_score = (rouge_1_f1 + rouge_2_f1 + rouge_l_f1) / 3\n",
    "    return average_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb2cb387-0d83-4301-98cb-55cb1c1f7bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the answers at the specific index (10)\n",
    "index = 10\n",
    "answer_llm = df.loc[index, 'answer_llm']\n",
    "answer_orig = df.loc[index, 'answer_orig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e1d455c-2bd7-4697-a07f-d3313a0e2c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores at index 10: {'rouge-1': {'r': 0.45454545454545453, 'p': 0.45454545454545453, 'f': 0.45454544954545456}, 'rouge-2': {'r': 0.21621621621621623, 'p': 0.21621621621621623, 'f': 0.21621621121621637}, 'rouge-l': {'r': 0.3939393939393939, 'p': 0.3939393939393939, 'f': 0.393939388939394}}\n",
      "Average ROUGE score (ROUGE-1, ROUGE-2, ROUGE-L) at index 10: 0.35490034990035496\n"
     ]
    }
   ],
   "source": [
    "# Compute the ROUGE scores\n",
    "scores = compute_rouge_scores(answer_llm, answer_orig)\n",
    "\n",
    "# Compute the average of ROUGE-1, ROUGE-2, and ROUGE-L scores\n",
    "average_rouge_score = compute_average_rouge(scores)\n",
    "\n",
    "print(f\"ROUGE scores at index {index}: {scores}\")\n",
    "print(f\"Average ROUGE score (ROUGE-1, ROUGE-2, ROUGE-L) at index {index}: {average_rouge_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e90d7b77-5bfc-4272-9750-5c0113e50f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store the ROUGE scores\n",
    "rouge_1_scores = []\n",
    "rouge_2_scores = []\n",
    "rouge_l_scores = []\n",
    "rouge_avg_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf772250-eb68-470f-84f5-91610d547605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ec4928a8834477b66170795ed9b86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through the DataFrame to compute ROUGE scores for each record\n",
    "for index, record in tqdm(df.iterrows(), total=len(df)):\n",
    "    scores = compute_rouge_scores(record['answer_llm'], record['answer_orig'])\n",
    "    \n",
    "    rouge_1 = scores['rouge-1']['f']\n",
    "    rouge_2 = scores['rouge-2']['f']\n",
    "    rouge_l = scores['rouge-l']['f']\n",
    "    rouge_avg = (rouge_1 + rouge_2 + rouge_l) / 3\n",
    "    \n",
    "    rouge_1_scores.append(rouge_1)\n",
    "    rouge_2_scores.append(rouge_2)\n",
    "    rouge_l_scores.append(rouge_l)\n",
    "    rouge_avg_scores.append(rouge_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "959578b3-9109-4f2c-9cfc-fc589ec80e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the ROUGE scores\n",
    "rouge_scores_df = pd.DataFrame({\n",
    "    'rouge-1': rouge_1_scores,\n",
    "    'rouge-2': rouge_2_scores,\n",
    "    'rouge-l': rouge_l_scores,\n",
    "    'rouge-avg': rouge_avg_scores\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0ed476a-2308-43de-bf2c-2ff8fe88a9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average ROUGE-2 score across all records is: 0.20696501983423318\n"
     ]
    }
   ],
   "source": [
    "# Compute the average ROUGE-2 score across all records\n",
    "average_rouge_2 = rouge_scores_df['rouge-2'].mean()\n",
    "\n",
    "print(f\"The average ROUGE-2 score across all records is: {average_rouge_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd7ffad-d4fe-46f0-99a9-4ae9a5572ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
